# ğŸ¤– RAGBot Session â€“ Multi-user Document Q&A Chatbot with Ollama

**RAGBot Session** is a lightweight, session-isolated RAG (Retrieval-Augmented Generation) chatbot that lets **each user upload their own documents** and interact with a private, context-aware AI assistant â€” all powered locally with [Ollama](https://ollama.com/).

---

### ğŸš€ Features

- ğŸ“ Per-user document upload and isolated knowledgebase
- ğŸ¤– Chat interface powered by local LLM (e.g., Mistral) via Ollama
- ğŸ“„ Supports multiple formats: PDF, DOCX, TXT, CSV, and Markdown
- ğŸ’¬ Gradio web UI with real-time updates and session memory
- ğŸ” Safe prompt: model answers only from document context
- ğŸ§  Embedding model: `nomic-embed-text` via Ollama

---

### ğŸ““ Run It Instantly on Colab

Try it in your browser (GPU recommended):  
ğŸ‘‰ [Open in Colab](https://colab.research.google.com/drive/1GwU-U46PQs0raLykUhWgkVUffY4VJaOl?usp=sharing)

---

### ğŸ“‚ Supported File Types

| Type | Extension |
|------|-----------|
| PDF  | `.pdf`    |
| Word | `.docx`   |
| Text | `.txt`    |
| CSV  | `.csv`    |
| Markdown | `.md` |

---

### ğŸ›  Tech Stack

- **LLM backend**: [Ollama](https://ollama.com/)
- **Embeddings**: `nomic-embed-text`
- **Vector DB**: Chroma
- **Framework**: LangChain
- **UI**: Gradio
- **Runtime**: Google Colab / Local

---

### ğŸ’¡ Use Cases

- Product document chatbot per user
- Multi-user document Q&A systems
- Custom knowledge assistants for teams
- Private, offline RAG-powered helpdesk

---

### ğŸ“Œ How It Works

1. Each user uploads their documents (multi-format)
2. App indexes documents and creates an isolated vector DB
3. Questions are answered strictly from the relevant content
4. No cross-user data mixing â€” each session is sandboxed

---

### ğŸ“„ License

MIT â€” Free to use, modify, and distribute.

---

### ğŸ™‹â€â™‚ï¸ Author

Built with ![AI](https://img.shields.io/badge/-AI%20Power-6f42c1?style=flat&logo=openai&logoColor=white) by [ritik-dev](https://github.com/ritik-dev)
